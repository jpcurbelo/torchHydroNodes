# --- Model configurations --- #
# Conceptual model to use [exphydro, ...
# Hybrid model: exphydro + mlp -> M100
# Ref: exphydro -> https://hess.copernicus.org/articles/26/5085/2022/
hybrid_model: exphydroM100
concept_model: exphydro

# Method to solve the ODEs with torchdiffeq [bosh3, rk4, dopri5, euler, rk2, adaptive_heun]
odesmethod: euler
time_step: 0.5

# If True, carries the final state (e.g., s_snow, s_water) from the previous batch as the initial condition for the next batch.
carryover_state: False

# Files to specify training, validation and test basins
basin_file: 59_basin_file_sample_ok.txt
# basin_file: cluster_files/569_basins_17clusters/569_basin_file_cluster2of17_46.txt
# basin_file: cluster_files/569_basins_17clusters/569_basin_file_cluster2of17_46_5first.txt
# basin_file: cluster_files/569_basins_17clusters/569_basin_file_cluster2of17_46_10first.txt
# basin_file: cluster_files/569_basins_17clusters/569_basin_file_cluster2of17_46_20first.txt


# # Number of first and random basins to use for training and testing
# n_random_basins: 10

# --- Data configurations --- #
# Dataset to use for training and testing [camelsus, summaca]
data_dir: M0_results_569basins_1980_2010_RK23

# nn_model_dir: cluster2of17_pretrainer_mlp_32x5_static_240811_165218
# nn_model_dir: cluster2of17_5f_pretrainer_mlp_32x5_240808_113706
# nn_model_dir: cluster2of17_5f_pretrainer_mlp_32x5_static_240808_133240
# nn_model_dir: cluster2of17_20f_pretrainer_mlp_32x5_static_240808_135224
# nn_model_dir: cluster2of17_20f_pretrainer_mlp_32x5_static_240811_165110

# If not nn_model_dir, specify the model and parameters to use:
###############################################################
# NN model to use [mlp, lstm]
nn_model: mlp

# # Length of the input sequence
# seq_length: 270

nn_dynamic_inputs:
  - s_snow
  - s_water
  - prcp
  - tmean

nn_mech_targets:
  - ps_bucket
  - pr_bucket
  - m_bucket
  - et_bucket
  - q_bucket

target_variables: 
  - obs_runoff

# --- Data configurations --- #
# Dataset to use for training and testing [camelsus, summaca]
dataset: camelsus
# concept_data_dir: ../../../../../gladwell/hydrology/SUMMA/summa-ml-models/CAMELS_US
## See file src/utils/data_dir.yml for more details
concept_data_dir: data_dir_camelsus

static_attributes:
  - elev_mean
  - slope_mean
  - area_gages2
  - frac_forest
  - lai_max
  - lai_diff
  - gvf_max
  - gvf_diff
  - soil_depth_pelletier
  - soil_depth_statsgo
  - soil_porosity
  - soil_conductivity
  - max_water_content
  - sand_frac
  - silt_frac
  - clay_frac
  # - carbonate_rocks_frac
  - geol_permeability
  - p_mean
  - pet_mean
  - aridity
  - frac_snow
  - high_prec_freq
  - high_prec_dur
  - low_prec_freq
  - low_prec_dur
  - p_seasonality

# Hidden layers for the NN model
hidden_size: 
  - 128
  - 128
  - 128

loss_pretrain: mse
lr_pretrain: 0.001
epochs_pretrain: 200
###############################################################

scale_target_vars: True

# --- Training configurations --- #

# # Period to train, validate and test the model (they should be consecutive)
train_start_date: "01/10/1980"
train_end_date: "30/09/2000"
valid_start_date: "01/10/2000"
valid_end_date: "30/09/2010"

# Loss function to use [mse, nse, nse-nh]
loss: nse-nh

# Number of epochs to train the model
epochs: 100

# Patience for early stopping
patience: 20

# If a value, clips the gradients during training to that norm.
clip_gradient_norm: 1.0

# Batch size for training (if -1, it will be only one batch for the whole dataset)
# batch_size: 7304
# batch_size: 512
batch_size: 256

# Optimizer to use [adam, sgd]
optimizer: adam

# # Learning rate for the optimizer
learning_rate: 0.0001
# learning_rate:
#   initial: 0.001
#   decay: 0.5
#   decay_step_fraction: 2  # Decay step fraction (e.g., N-> 1/N of the total epochs

## --- Run configurations --- ##
# Experiment name, used as folder name
# experiment_name: cluster2of17_hybrid_mlp_32x5_256b_static_nse-nh
# experiment_name: cluster2of17_5f_hybrid_mlp_32x5_256b_nse-nh
# experiment_name: cluster2of17_20f_hybrid_mlp_32x5_256b_static_nse-nh
# experiment_name: sample59basins_hybrid_mlp_32x3_256b_static
experiment_name: sample59basins_hybrid_mlp_128x3_256b_static


# which GPU (id) to use [in format of cuda:0, cuda:1 etc, or cpu or None]
device: cpu

# Set seed for reproducibility
seed: 111

# Set precision for the model [float32, float64]
precision: float32

# Number of parallel workers used in the data pipeline
num_workers: 16

# Verbose level [0, 1] (0: only log info messages, don't show progress bars, 1: show progress bars)
verbose: 1

# If a value and greater than 0, logs n random basins as figures after pretraining the NN model
# If list of basins, logs the specified basins: format is either '01013500' or 1013500
log_n_basins: 5
  # - 1013500
  # # - 6431500
  # # 2
  # # 1

# If a value and greater than 0, logs figures and metrics, and save model after each n epochs
log_every_n_epochs: 20

# Metrics to use for evaluation (after training)
metrics:
  - NSE
  - Alpha-NSE
  - Beta-NSE
  - FHV
  - FMS
  - FLV
  - KGE
  - Beta-KGE
  - Peak-Timing
  - Peak-MAPE
  - Pearson-r