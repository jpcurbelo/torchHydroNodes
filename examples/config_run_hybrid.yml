# --- Model configurations --- #
# Conceptual model to use [exphydro, ...
# Hybrid model: exphydro + mlp -> M100
# Ref: exphydro -> https://hess.copernicus.org/articles/26/5085/2022/
hybrid_model: exphydroM100
concept_model: exphydro
odesmethod: bosh3

# Files to specify training, validation and test basins
basin_file: 1_basin_file.txt

# --- Data configurations --- #
# Dataset to use for training and testing [camelsus, summaca]
data_dir: M0_results_569basins_1980_2010
# nn_model_dir: NNpretrainer_250basins_1980_2010
nn_model_dir: NNpretrainer_01013500_1980_2010_1000ep
# nn_model_dir: NNpretrainer_06431500_1980_2010

scale_target_vars: True

# --- Training configurations --- #

# # Period to train, validate and test the model (they should be consecutive)
train_start_date: "01/10/1980"
train_end_date: "30/09/2000"
valid_start_date: "01/10/2000"
valid_end_date: "30/09/2010"
test_start_date: "01/10/2000"
test_end_date: "30/09/2010"

# train_start_date: "01/10/1995"
# train_end_date: "30/09/2000"
# valid_start_date: "01/10/2000"
# valid_end_date: "30/09/2003"
# test_start_date: "01/10/2000"
# test_end_date: "30/09/2003"

# Loss function to use [mse, nse, nse-nh]
loss: nse

# Number of epochs to train the model
epochs: 100

# Patience for early stopping
patience: 10

# If a value, clips the gradients during training to that norm.
clip_gradient_norm: 1.0

# Batch size for training (if -1, it will be only one batch for the whole dataset)
batch_size: 7304
# batch_size: 512

# Optimizer to use [adam, sgd]
optimizer: adam

# # Learning rate for the optimizer
# learning_rate: 0.001
learning_rate:
  initial: 0.001
  decay: 0.5
  decay_step_fraction: 2  # Decay step fraction (e.g., 1/4 of the total epochs

## --- Run configurations --- ##
# Experiment name, used as folder name
experiment_name: ZZtrain_hybrid_run

# which GPU (id) to use [in format of cuda:0, cuda:1 etc, or cpu or None]
device: cpu

# Set seed for reproducibility
seed: 1111

# Set precision for the model [float32, float64]
precision: float32

# Number of parallel workers used in the data pipeline
num_workers: 16

# Verbose level [0, 1] (0: only log info messages, don't show progress bars, 1: show progress bars)
verbose: 1


# If a value and greater than 0, logs n random basins as figures after pretraining the NN model
# If list of basins, logs the specified basins: format is either '01013500' or 1013500
log_n_basins:
  - 1013500
  # - 6431500
  # 2
  # 1

# If a value and greater than 0, logs figures and metrics, and save model after each n epochs
log_every_n_epochs: 5

# Metrics to use for evaluation (after training)
metrics:
  - NSE
  - Alpha-NSE
  - Beta-NSE
  - FHV
  - FMS
  - FLV
  - KGE
  - Beta-KGE
  - Peak-Timing
  - Peak-MAPE
  - Pearson-r