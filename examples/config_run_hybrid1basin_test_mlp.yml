# --- Model configurations --- #
# Conceptual model to use [exphydro, ...
# Hybrid model: exphydro + mlp -> M100
# Ref: exphydro -> https://hess.copernicus.org/articles/26/5085/2022/
hybrid_model: exphydroM100
concept_model: exphydro
# Method to solve the ODEs with torchdiffeq [bosh3, rk4, dopri5, euler, adaptive_heun, midpoint]
# odesmethod: bosh3
odesmethod: euler
time_step: 1.0

# If True, carries the final state (e.g., s_snow, s_water) from the previous batch as the initial condition for the next batch.
carryover_state: False

# Files to specify training, validation and test basins
basin_file: 1_basin_file.txt
# basin_file: 1_basin_fileB.txt

# --- Data configurations --- #
# Dataset to use for training and testing [camelsus, summaca]
data_dir: M0_results_569basins_1980_2010_RK23

# nn_model_dir: ZZZZ1basin_pretrainer_mlp_32x5_lr2_200ep_01013500_240826_134921
# # # nn_model_dir: ZZZZ1basin_pretrainer_mlp_32x5_lr2_200ep_01013500_240826_151012_RELU
# nn_model_dir: ZZZZ1basin_pretrainer_mlp_32x5_lr2_200ep_06431500_240826_144437

# If not nn_model_dir, specify the model and parameters to use:
###############################################################
# NN model to use [mlp, lstm]
nn_model: mlp

# # Length of the input sequence
# seq_length: 270

nn_dynamic_inputs:
  - s_snow
  - s_water
  - prcp
  - tmean

nn_mech_targets:
  - ps_bucket
  - pr_bucket
  - m_bucket
  - et_bucket
  - q_bucket

target_variables: 
  - obs_runoff

# Hidden layers for the NN model
hidden_size: 
  - 32
  - 32
  - 32
  - 32
  - 32

loss_pretrain: mse
lr_pretrain: 0.001
epochs_pretrain: 500
###############################################################

scale_target_vars: True

# --- Training configurations --- #

# Period to train, validate and test the model (they should be consecutive)
train_start_date: "01/10/1980"
train_end_date: "30/09/2000"
valid_start_date: "01/10/2000"
valid_end_date: "30/09/2010"

# train_start_date: "01/10/1995"
# train_end_date: "30/09/2000"
# valid_start_date: "01/10/2000"
# valid_end_date: "30/09/2005"

# Loss function to use [mse, nse, nse-nh]
loss: nse

# Number of epochs to train the model
epochs: 50

# Patience for early stopping
patience: 30

# If a value, clips the gradients during training to that norm.
clip_gradient_norm: 1.0

# Batch size for training (if -1, it will be only one batch for the whole train time-series)
# batch_size: 1024
# batch_size: 512
batch_size: 256
# batch_size: 128
# batch_size: -1
# batch_size: 914   #1827
# batch_size: 610

# # Dropout rate for the NN model
# dropout: 0.4

# Optimizer to use [adam, sgd]
optimizer: adam

# # Learning rate for the optimizer
learning_rate: 0.0001
# learning_rate:
#   initial: 0.00001
#   decay: 0.5
#   decay_step_fraction: 4  # Decay step fraction (e.g., N-> 1/N of the total epochs
# learning_rate:
#   initial: 0.0001
#   decay: 0.1
#   decay_step_fraction: 3  # Decay step fraction (e.g., 1/3 of the total epochs

## --- Run configurations --- ##
# Experiment name, used as folder name
# experiment_name: _ZZZZ_1basin_hybrid_mlp_32x5_euler_lr34_200ep
# experiment_name: _ZZZZ_1basin_hybrid_mlp_32x5_bosh3_lr34_200ep
# experiment_name: ZZZZZ_1basin_hybrid_mlp_32x5_euler5d_lr4_100ep
# experiment_name: ZZZZZ_1basin_hybrid_mlp_32x5_bosh3_lr4_400ep
# experiment_name: _AAAAA_1basin_hybrid_mlp_32x5_euler1d_lr4_100ep_7305b_load_pretrain

# experiment_name: _AAAAA_1basin_hybrid_mlp_32x5_euler1d_lr4x_400ep_256b_load_pretrain
# experiment_name: _AAAAA_1basin_hybrid_mlp_32x5_euler1d_lr4x_400ep_256b
# experiment_name: _AAAAA_1basin_hybrid_mlp_32x5_euler1d_lr4x_400ep_7305b
# experiment_name: _AAAAA_1basin_hybrid_mlp_32x5_euler1d_lr4x_400ep_7305b_load_pretrain

# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_512b_euler1d_lr4_100ep_mean-loss
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_400ep_500pre
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_512b_euler1d_lr4_100ep_200pre
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_512b_euler1d_lr4_400ep_500pre
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_100ep_200pre_mse
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_512b_euler1d_lr4_100ep_200pre_mse
# experiment_name: _AAAA_1basin_hybrid_mlp_32x5_64b_euler1d_lr4_200ep_500pre

# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_100ep_500pre
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_200ep_500pre_oldOverLap
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_512b_euler1d_lr4_200ep_500pre_oldOverLap
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_100ep_500pre_notLastBatch
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr5_100ep_500pre
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr34_100ep_500pre
# experiment_name: _BBBB_1basin_hybrid_mlp_32x5_256b_euler1d_lr45_100ep_500pre


# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_200ep_500pre_lr2_noOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_200ep_500pre_lr2_newOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr4_200ep_500pre_lr3_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr45_200ep_500pre_lr3_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler1d_lr4455_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler05d_lr4455_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_euler05d_lr4_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_bosh3_lr4_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_256b_bosh3_lr4455_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_euler1d_lr4_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_bosh3_lr4_200ep_500pre_lr2_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_bosh3_lr4556_200ep_1000pre_lr3_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_euler1d_lr4556_200ep_1000pre_lr3_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_euler05d_lr4556_200ep_1000pre_lr3_oldOverLa
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_euler1d_lr4556_400ep_1000pre_lr3_oldOverLa
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_bosh3_lr5667_400ep_1000pre_lr3_oldOverLap
# experiment_name: _CCCC_1basin_hybrid_mlp_32x5_7305b_euler1d_lr5667_400ep_1000pre_lr3_oldOverLap

# experiment_name: _DDDD_1basin_hybrid_mlp_32x5_7305b_bosh3_lr4_200ep_1000pre_lr3_oldOverLap
# experiment_name: _DDDD_1basin_hybrid_mlp_32x5_7305b_euler1d_lr4_200ep_1000pre_lr3_oldOverLap
# experiment_name: _DDDD_1basin_hybrid_mlp_32x5_7305b_euler05d_lr4_200ep_1000pre_lr3_oldOverLap
# experiment_name: _DDDD_1basin_hybrid_mlp_32x5_7305b_euler1d_lr456_300ep_1000pre_lr3_oldOverLap


# experiment_name: _____1basin_hybrid_mlp_carryoverYES
experiment_name: _____1basin_hybrid_mlp_carryoverNO


# which GPU (id) to use [in format of cuda:0, cuda:1 etc, or cpu or None]
device: cpu

# Set seed for reproducibility
seed: 1111

# Set precision for the model [float32, float64]
precision: float32

# Number of parallel workers used in the data pipeline
num_workers: 16

# Verbose level [0, 1] (0: only log info messages, don't show progress bars, 1: show progress bars)
verbose: 1


# If a value and greater than 0, logs n random basins as figures after pretraining the NN model
# If list of basins, logs the specified basins: format is either '01013500' or 1013500
log_n_basins: 1
  # - 1013500
  # - 6431500

# If a value and greater than 0, logs figures and metrics, and save model after each n epochs
log_every_n_epochs: 10

# Metrics to use for evaluation (after training)
metrics:
  - NSE
  - Alpha-NSE
  - Beta-NSE
  - FHV
  - FMS
  - FLV
  - KGE
  - Beta-KGE
  - Peak-Timing
  - Peak-MAPE
  - Pearson-r