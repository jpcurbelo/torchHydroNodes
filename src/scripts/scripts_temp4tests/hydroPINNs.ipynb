{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/ame805/torchHydroNodes\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Make sure code directory is in path,\n",
    "# Add the parent directory of your project to the Python path\n",
    "project_dir = str(current_dir.parent.parent.parent)\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "from src.thn_run import (\n",
    "    _load_cfg_and_ds,\n",
    "    get_basin_interpolators,\n",
    "    get_calibration_dataset,\n",
    ")\n",
    "\n",
    "from src.modelzoo_concept import get_concept_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"examples/config_run_calibrate_test.yml\"\n",
    "input_vars = ['prcp', 'tmean', 'dayl']\n",
    "output_vars = ['obs_runoff']\n",
    "\n",
    "HIDDEN_LAYERS = [64, 64, 64, 64, 64]\n",
    "\n",
    "LR = 1e-3\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydrologyPINN(nn.Module):\n",
    "    \"\"\"\n",
    "    A PyTorch neural network model for hydrology-based physics-informed neural networks (PINNs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, \n",
    "                 hidden_layers=HIDDEN_LAYERS, params_bounds=None):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with variable hidden layers.\n",
    "        \n",
    "        Args:\n",
    "            input_size (int): The number of input features.\n",
    "            output_size (int): The number of output features.\n",
    "            hidden_layers (list of int): A list where each element represents the number of neurons in each hidden layer.\n",
    "            params_bounds (list of tuples): A list of tuples where each tuple represents the lower and upper bounds for each parameter\n",
    "        \"\"\"\n",
    "        super(HydrologyPINN, self).__init__()\n",
    "        \n",
    "        # Set up the neural network layers\n",
    "        layers = [nn.Linear(input_size, hidden_layers[0]), nn.Tanh()]\n",
    "        \n",
    "        # Add hidden layers\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            layers.append(nn.Linear(hidden_layers[i-1], hidden_layers[i]))\n",
    "            layers.append(nn.Tanh())\n",
    "        \n",
    "        # Add output layer\n",
    "        layers.append(nn.Linear(hidden_layers[-1], output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Now initialize parameters with the same order guaranteed\n",
    "        self.params = nn.ParameterDict(OrderedDict({\n",
    "            name: nn.Parameter(\n",
    "                torch.Tensor(1).uniform_(bounds[0], bounds[1]), requires_grad=True\n",
    "            ) for name, bounds in params_bounds.items()\n",
    "        }))\n",
    "        self.params_bounds = params_bounds  # Store bounds for clamping\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    def get_clamped_params(self):\n",
    "        \"\"\"\n",
    "        Return parameters clamped within their bounds.\n",
    "        \"\"\"\n",
    "        return {name: torch.clamp(param, *self.params_bounds[name]) for name, param in self.params.items()}\n",
    "\n",
    "    \n",
    "# Define the data loss and physics-based loss functions\n",
    "def data_loss(predicted, observed):\n",
    "\n",
    "    return nn.MSELoss()(predicted, observed)\n",
    "\n",
    "def physics_loss(model, basin, predicted_params, observed):\n",
    "\n",
    "    # Calculate terms based on your differential equations (requires details of ds/dt, etc.)\n",
    "    simulated = model.run(basin, basin_params=predicted_params, use_grad=True)\n",
    "    physics_penalty = simulated[-1] - observed\n",
    "\n",
    "    return torch.mean(physics_penalty ** 2)\n",
    "\n",
    "# Combine losses for the PINNs approach\n",
    "def pinn_loss(predicted, observed, predicted_params, model, basin):\n",
    "\n",
    "    return data_loss(predicted, observed) + physics_loss(model, basin, predicted_params, observed)\n",
    "\n",
    "\n",
    "def plot_results(observed, predicted, epoch):\n",
    "    plt.plot(observed, label='Observed', color='blue')\n",
    "    plt.plot(predicted.detach().cpu().numpy(), label='Predicted', \n",
    "             color='red', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title(f'Observed vs. Predicted (epoch {epoch})')\n",
    "    plt.savefig('pins_simulation.png')\n",
    "    plt.clf()\n",
    "\n",
    "# # Initialize the plot for observed vs predicted\n",
    "# def init_plot(observed):\n",
    "#     plt.ion()\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     ax.plot(observed, label='Observed', color='blue')\n",
    "#     pred_line, = ax.plot([], label='Predicted', color='orange')\n",
    "#     ax.legend()\n",
    "#     ax.set_xlabel('Time Step')\n",
    "#     ax.set_ylabel('Values')\n",
    "#     ax.set_title('Observed vs. Predicted')\n",
    "#     return fig, ax, pred_line\n",
    "\n",
    "# # Update the plot with new predictions\n",
    "# def update_plot(pred_line, predicted, fig):\n",
    "#     pred_line.set_ydata(predicted.detach().cpu().numpy())  # Update the y-data for predicted\n",
    "#     pred_line.set_xdata(range(len(predicted)))  # Update the x-data in case of changes in length\n",
    "#     plt.draw()\n",
    "#     plt.pause(0.1)  # Pause briefly to update the plot\n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Loading the config file and the dataset\n",
      "-- Using device: cuda:0 --\n",
      "Setting seed for reproducibility: 1111\n",
      "-- Loading basin dynamics into xarray data set.\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 10.42it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg, dataset = _load_cfg_and_ds(Path(project_dir) / cfg_file, model='conceptual')\n",
    "\n",
    "# Get the basin interpolators\n",
    "interpolators = get_basin_interpolators(dataset, cfg, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 302.20135498046875, params: [986.0253, 1380.3936, 0.2572, 2083.1235, 132.0493, 9.5271, 7.589, -5.8381]\n",
      "Epoch 2/50, Loss: 266.2840881347656, params: [986.0253, 1380.3936, 0.2472, 2083.1335, 132.0393, 9.5171, 7.599, -5.8281]\n",
      "Epoch 3/50, Loss: 300.8600769042969, params: [986.0253, 1380.3936, 0.2396, 2083.1262, 132.0318, 9.5244, 7.5916, -5.8354]\n",
      "Epoch 4/50, Loss: 315.8741760253906, params: [986.0253, 1380.3936, 0.2338, 2083.1206, 132.026, 9.5302, 7.5859, -5.8412]\n",
      "Epoch 5/50, Loss: 324.9161682128906, params: [986.0253, 1380.3936, 0.2292, 2083.116, 132.0213, 9.5349, 7.5812, -5.8459]\n",
      "Epoch 6/50, Loss: 284.9862365722656, params: [986.0253, 1380.3936, 0.2254, 2083.1121, 132.0173, 9.5389, 7.5772, -5.8498]\n",
      "Epoch 7/50, Loss: 331.5143127441406, params: [986.0253, 1380.3936, 0.2221, 2083.1086, 132.0139, 9.5423, 7.5738, -5.8532]\n",
      "Epoch 8/50, Loss: 316.1024169921875, params: [986.0253, 1380.3936, 0.2192, 2083.1057, 132.0109, 9.5453, 7.5708, -5.8562]\n",
      "Epoch 9/50, Loss: 315.001953125, params: [986.0253, 1380.3936, 0.2167, 2083.103, 132.0083, 9.5479, 7.5682, -5.8588]\n",
      "Epoch 10/50, Loss: 301.917236328125, params: [986.0253, 1380.3936, 0.2144, 2083.1006, 132.0059, 9.5503, 7.5658, -5.8611]\n",
      "Epoch 11/50, Loss: 296.8480224609375, params: [986.0253, 1380.3936, 0.2124, 2083.0984, 132.0038, 9.5523, 7.5638, -5.8631]\n",
      "Epoch 12/50, Loss: 298.3160095214844, params: [986.0253, 1380.3936, 0.2106, 2083.0964, 132.002, 9.5542, 7.5619, -5.865]\n"
     ]
    }
   ],
   "source": [
    "for basin in tqdm(dataset.basins, disable=cfg.disable_pbar, file=sys.stdout):\n",
    "    # # Skip basins that have already been processed\n",
    "    # if basin in processed_basins:\n",
    "    #     print(f\"Basin {basin} already processed, skipping.\")\n",
    "    #     continue\n",
    "\n",
    "    ds_calib, time_idx0 = get_calibration_dataset(cfg, dataset, basin)\n",
    "    \n",
    "    time_idx0 = 0\n",
    "    model_concept = get_concept_model(cfg, ds_calib, interpolators, time_idx0,\n",
    "                                        dataset.scaler, odesmethod=cfg.odesmethod)\n",
    "    \n",
    "    # Get the input and output sizes\n",
    "    input_size = len(input_vars)\n",
    "    output_size = len(output_vars)\n",
    "    \n",
    "    # Get the parameter bounds\n",
    "    params_bounds = OrderedDict(model_concept.cfg.params_bounds)\n",
    "    \n",
    "    # Crethe PINN model\n",
    "    model_pinn = HydrologyPINN(input_size, output_size, \n",
    "                               hidden_layers=HIDDEN_LAYERS, params_bounds=params_bounds)\n",
    "    optimizer = optim.Adam(model_pinn.parameters(), lr=LR)\n",
    "\n",
    "    # DS to DF\n",
    "    df_calib = ds_calib.to_dataframe()\n",
    "\n",
    "    # Get the observed data\n",
    "    observed_data = torch.tensor(df_calib[output_vars].values, dtype=torch.float32)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        model_pinn.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: Simulate data through the network\n",
    "        input_data = torch.tensor(df_calib[input_vars].values, dtype=torch.float32)\n",
    "\n",
    "        predicted_data = model_pinn(input_data)\n",
    "\n",
    "        # Update the plot with new predicted values\n",
    "        plot_results(observed_data, predicted_data, epoch+1)\n",
    "\n",
    "        # Clamp the parameters within their bounds\n",
    "        predicted_params = model_pinn.get_clamped_params()\n",
    "\n",
    "        # Extract the parameters from the model\n",
    "        basin_params = [predicted_params[param] for param in predicted_params.keys()]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = pinn_loss(predicted_data, observed_data, basin_params, model_concept, basin)\n",
    "\n",
    "        # Backward pass: Compute the gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Convert basin_params to list if it's a PyTorch tensor, then extract and round values\n",
    "        params_list = (\n",
    "            [round(param.item(), 4) for param in basin_params] if isinstance(basin_params, torch.Tensor) else\n",
    "            [round(param.item(), 4) if isinstance(param, torch.Tensor) else round(param, 4) for param in basin_params]\n",
    "        )\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item()}, params: {params_list}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-hydronodes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
