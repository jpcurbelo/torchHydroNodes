{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a hybrid model - MLP/LSTM\n",
    "\n",
    "In this tutorial, we demonstrate the steps to train a hybrid model using MLP or LSTM as the Neural Network component. The training data is derived from the pre-processed outputs generated after running the conceptual model. The Hybrid Model is trained to predict $Q$ (runoff) by matching the observed data.\n",
    "\n",
    "**IMPORTANT**: While this tutorial uses a file listing 2 basins, it does not demonstrate a multi-basin model. Instead, a single-basin model is run for each basin individually.\n",
    "\n",
    "**Before we start**\n",
    "\n",
    "- This tutorial is rendered from a Jupyter notebook that is hosted on GitHub. If you'd like to run the code yourself, you can access the notebook and configuration files directly from the repository: [03-TrainHybridModel](https://github.com/jpcurbelo/torchHydroNodes/tree/master/tutorials/03-TrainHybridModel).\n",
    "\n",
    "- To run this notebook locally, ensure you have completed the setup steps outlined in [Getting started](https://torchhydronodes.readthedocs.io/en/latest/usage/getting_started.html). These steps include setting up the environment, installing the required packages, and preparing the data files necessary for the tutorial.\n",
    "\n",
    "- **Dependency on a Previous Tutorial**: Before running this tutorial, you must complete the [01-RunConceptModel Tutorial](https://torchhydronodes.readthedocs.io/en/latest/tutorials/run-concept-model.html). After completing it:\n",
    "\n",
    "    1- Move the generated run folder to ``src/data``.\n",
    "\n",
    "    2- Update the ``data_dir`` field in the ``config_run_train_mlp.yml``  ([here](https://github.com/jpcurbelo/torchHydroNodes/blob/master/tutorials/03-TrainHybridModel/config_run_train_mlp.yml)) (or ``config_run_train_lstm.yml``  ([here](https://github.com/jpcurbelo/torchHydroNodes/blob/master/tutorials/03-TrainHybridModel/config_run_train_lstm.yml))) file to point to this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Dynamically set the project directory based on the notebook's location\n",
    "notebook_dir = Path().resolve()\n",
    "project_dir = str(notebook_dir.parent.parent)  # Adjust based on your project structure\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from src.thn_run import (\n",
    "    _load_cfg_and_ds,\n",
    "    get_basin_interpolators\n",
    ")\n",
    "\n",
    "from src.modelzoo_concept import get_concept_model\n",
    "from src.modelzoo_nn import (\n",
    "    get_nn_model,\n",
    "    get_nn_pretrainer,\n",
    ")\n",
    "from src.modelzoo_hybrid import (\n",
    "    get_hybrid_model,\n",
    "    get_trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "\n",
    "Feel free to run and explore both *nn_type = 'mlp'* and *nn_type = 'lstm'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_type = 'mlp'  \n",
    "# nn_type = 'lstm'\n",
    "\n",
    "config_file = f'config_run_train_{nn_type}.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load main config file\n",
    "\n",
    "This step is essential when running multiple single-basin models. Refer to *src/scripts_paper/run_hybrid_trainer_single_all_mlp.py* for the implementation. A parallelized version of the code demonstrated in this tutorial is also available for more efficient execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01013500', '01022500', '01030500', '06431500']\n"
     ]
    }
   ],
   "source": [
    "# Load the MAIN configuration file\n",
    "if Path(config_file).exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "else:\n",
    "    raise FileNotFoundError(f'Configuration file {config_file} not found!')\n",
    "    \n",
    "# Read basin list\n",
    "with open(cfg['basin_file'], 'r') as f:\n",
    "    all_basins = [basin.strip() for basin in f.readlines()]\n",
    "\n",
    "print(all_basins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train hybrid model for each basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Loading the config file and the dataset\n",
      "-- Using device: cpu --\n",
      "Setting seed for reproducibility: 111\n",
      "cfg.nn_model_dir is not defined - parameters MUST be defined in the config file\n",
      "-- Loading basin dynamics into xarray data set.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.59it/s]\n",
      "------------------------------------------------------------\n",
      "-- Pretraining the neural network model -- (cpu)\n",
      "------------------------------------------------------------\n",
      "# Epoch 00001: 100%|██████████| 29/29 [00:00<00:00, 120.84it/s, Loss=1.0589e+00]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "# Epoch 00002: 100%|██████████| 29/29 [00:00<00:00, 152.34it/s, Loss=3.4281e-01]\n",
      "# Epoch 00003: 100%|██████████| 29/29 [00:00<00:00, 143.18it/s, Loss=1.8930e-01]\n",
      "# Epoch 00004: 100%|██████████| 29/29 [00:00<00:00, 160.47it/s, Loss=1.3642e-01]\n",
      "# Epoch 00005: 100%|██████████| 29/29 [00:00<00:00, 167.77it/s, Loss=1.1274e-01]\n",
      "# Epoch 00006: 100%|██████████| 29/29 [00:00<00:00, 170.74it/s, Loss=8.4502e-02]\n",
      "# Epoch 00007: 100%|██████████| 29/29 [00:00<00:00, 177.40it/s, Loss=8.5674e-02]\n",
      "# Epoch 00008: 100%|██████████| 29/29 [00:00<00:00, 172.84it/s, Loss=4.5157e-02]\n",
      "# Epoch 00009: 100%|██████████| 29/29 [00:00<00:00, 166.84it/s, Loss=3.9378e-02]\n",
      "# Epoch 00010: 100%|██████████| 29/29 [00:00<00:00, 162.76it/s, Loss=3.3307e-02]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "# Epoch 00011: 100%|██████████| 29/29 [00:00<00:00, 152.98it/s, Loss=3.2391e-02]\n",
      "# Epoch 00012: 100%|██████████| 29/29 [00:00<00:00, 162.90it/s, Loss=2.7244e-02]\n",
      "# Epoch 00013: 100%|██████████| 29/29 [00:00<00:00, 163.84it/s, Loss=2.6126e-02]\n",
      "# Epoch 00014: 100%|██████████| 29/29 [00:00<00:00, 169.55it/s, Loss=1.8526e-02]\n",
      "# Epoch 00015: 100%|██████████| 29/29 [00:00<00:00, 163.03it/s, Loss=3.0113e-02]\n",
      "# Epoch 00016: 100%|██████████| 29/29 [00:00<00:00, 163.12it/s, Loss=2.6183e-02]\n",
      "# Epoch 00017: 100%|██████████| 29/29 [00:00<00:00, 168.28it/s, Loss=2.6346e-02]\n",
      "# Epoch 00018: 100%|██████████| 29/29 [00:00<00:00, 162.75it/s, Loss=2.0164e-02]\n",
      "# Epoch 00019: 100%|██████████| 29/29 [00:00<00:00, 188.70it/s, Loss=1.7950e-02]\n",
      "# Epoch 00020: 100%|██████████| 29/29 [00:00<00:00, 206.54it/s, Loss=1.5267e-02]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "# Epoch 00021: 100%|██████████| 29/29 [00:00<00:00, 201.43it/s, Loss=1.5734e-02]\n",
      "# Epoch 00022: 100%|██████████| 29/29 [00:00<00:00, 205.35it/s, Loss=1.8016e-02]\n",
      "# Epoch 00023: 100%|██████████| 29/29 [00:00<00:00, 206.38it/s, Loss=2.8083e-02]\n",
      "# Epoch 00024: 100%|██████████| 29/29 [00:00<00:00, 118.44it/s, Loss=2.7260e-02]\n",
      "# Epoch 00025: 100%|██████████| 29/29 [00:00<00:00, 159.94it/s, Loss=1.5969e-02]\n",
      "# Epoch 00026: 100%|██████████| 29/29 [00:00<00:00, 158.20it/s, Loss=1.1404e-02]\n",
      "# Epoch 00027: 100%|██████████| 29/29 [00:00<00:00, 159.12it/s, Loss=1.4070e-02]\n",
      "# Epoch 00028: 100%|██████████| 29/29 [00:00<00:00, 160.94it/s, Loss=1.1904e-02]\n",
      "# Epoch 00029: 100%|██████████| 29/29 [00:00<00:00, 163.47it/s, Loss=1.8034e-02]\n",
      "# Epoch 00030: 100%|██████████| 29/29 [00:00<00:00, 158.61it/s, Loss=2.9080e-02]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "# Epoch 00031: 100%|██████████| 29/29 [00:00<00:00, 150.47it/s, Loss=2.1873e-02]\n",
      "# Epoch 00032: 100%|██████████| 29/29 [00:00<00:00, 158.82it/s, Loss=2.0210e-02]\n",
      "# Epoch 00033: 100%|██████████| 29/29 [00:00<00:00, 163.09it/s, Loss=2.6820e-02]\n",
      "# Epoch 00034: 100%|██████████| 29/29 [00:00<00:00, 164.18it/s, Loss=1.6065e-02]\n",
      "# Epoch 00035: 100%|██████████| 29/29 [00:00<00:00, 169.77it/s, Loss=1.4127e-02]\n",
      "# Epoch 00036: 100%|██████████| 29/29 [00:00<00:00, 168.24it/s, Loss=1.8038e-02]\n",
      "# Epoch 00037: 100%|██████████| 29/29 [00:00<00:00, 166.09it/s, Loss=1.8243e-02]\n",
      "# Epoch 00038: 100%|██████████| 29/29 [00:00<00:00, 163.01it/s, Loss=1.2418e-02]\n",
      "# Epoch 00039: 100%|██████████| 29/29 [00:00<00:00, 158.48it/s, Loss=1.2180e-02]\n",
      "# Epoch 00040: 100%|██████████| 29/29 [00:00<00:00, 161.59it/s, Loss=1.1189e-02]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "# Epoch 00041: 100%|██████████| 29/29 [00:00<00:00, 155.14it/s, Loss=1.3415e-02]\n",
      "# Epoch 00042: 100%|██████████| 29/29 [00:00<00:00, 160.08it/s, Loss=1.7245e-02]\n",
      "# Epoch 00043: 100%|██████████| 29/29 [00:00<00:00, 164.88it/s, Loss=1.9379e-02]\n",
      "# Epoch 00044: 100%|██████████| 29/29 [00:00<00:00, 158.17it/s, Loss=1.3128e-02]\n",
      "# Epoch 00045: 100%|██████████| 29/29 [00:00<00:00, 163.50it/s, Loss=1.5571e-02]\n",
      "# Epoch 00046: 100%|██████████| 29/29 [00:00<00:00, 164.12it/s, Loss=1.2147e-02]\n",
      "# Epoch 00047: 100%|██████████| 29/29 [00:00<00:00, 53.52it/s, Loss=1.8673e-02] \n",
      "# Epoch 00048: 100%|██████████| 29/29 [00:00<00:00, 152.52it/s, Loss=1.9846e-02]\n",
      "# Epoch 00049: 100%|██████████| 29/29 [00:00<00:00, 157.85it/s, Loss=1.3078e-02]\n",
      "# Epoch 00050: 100%|██████████| 29/29 [00:00<00:00, 154.36it/s, Loss=1.6706e-02]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "* Evaluating basin 01013500 (ds_train): 100%|██████████| 1/1 [00:00<00:00, 21.76it/s]\n",
      "* Evaluating basin 01013500 (ds_valid): 100%|██████████| 1/1 [00:00<00:00, 40.80it/s]\n",
      "------------------------------------------------------------\n",
      "-- Training the hybrid model on cpu --\n",
      "Initial learning rate: 1.00e-03\n",
      "------------------------------------------------------------\n",
      "# Epoch 00001 : 100%|██████████| 29/29 [00:19<00:00,  1.45it/s, Loss=-7.2505e-01]\n",
      "-- Saving the basin plots (epoch 1) | --\n",
      "* Plotting basin 01013500: 100%|██████████| 1/1 [00:13<00:00, 13.90s/it]\n",
      "-- Best model updated at epoch 1 with loss -7.2505e-01\n",
      "# Epoch 00002 : 100%|██████████| 29/29 [00:19<00:00,  1.46it/s, Loss=-7.8818e-01]\n",
      "-- Best model updated at epoch 2 with loss -7.8818e-01\n",
      "# Epoch 00003 :  45%|████▍     | 13/29 [00:09<00:11,  1.37it/s, Loss=-7.6193e-01]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m get_trainer(model_hybrid)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPretraining failed for basin \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbasin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/src/modelzoo_hybrid/basetrainer.py:136\u001b[0m, in \u001b[0;36mBaseHybridModelTrainer.train\u001b[0;34m(self, is_resume, max_nan_batches)\u001b[0m\n\u001b[1;32m    133\u001b[0m         inputs[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m carryover_s_water[:current_batch_size]  \u001b[38;5;66;03m# Adjust to match current batch size\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m q_sim, s_snow, s_water \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasin_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m nan_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misnan(q_sim)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nan_mask\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/src/modelzoo_hybrid/exphydroM100.py:116\u001b[0m, in \u001b[0;36mExpHydroM100.forward\u001b[0;34m(self, inputs, basin, use_grad)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# For MLP models (inputs are 2D):\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Set the initial conditions\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     y0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_snow[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_water[\u001b[38;5;241m0\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)    \u001b[38;5;66;03m#.to(self.device)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mode_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhybrid_model_mlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modesmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# 'rk4' 'midpoint'   'euler' 'dopri5' #rtol=1e-6, atol=1e-6\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# y = ode_solver(self.hybrid_model, y0=y0, t=time_series, method='rk4', rtol=1e-3, atol=1e-6)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Set the initial conditions\u001b[39;00m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torchdiffeq/_impl/odeint.py:79\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     76\u001b[0m solver \u001b[38;5;241m=\u001b[39m SOLVERS[method](func\u001b[38;5;241m=\u001b[39mfunc, y0\u001b[38;5;241m=\u001b[39my0, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     solution \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     event_t, solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mintegrate_until_event(t[\u001b[38;5;241m0\u001b[39m], event_fn)\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torchdiffeq/_impl/solvers.py:121\u001b[0m, in \u001b[0;36mFixedGridODESolver.integrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    119\u001b[0m     solution[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linear_interp(t0, t1, y0, y1, t[j])\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     solution[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cubic_hermite_interp(t0, y0, f0, t1, y1, f1, t[j])\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/venv-hydronodes/lib/python3.12/site-packages/torchdiffeq/_impl/misc.py:197\u001b[0m, in \u001b[0;36m_PerturbFunc.forward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Do nothing.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ame805/torchHydroNodes/src/modelzoo_hybrid/exphydroM100.py:254\u001b[0m, in \u001b[0;36mExpHydroM100.hybrid_model_mlp\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    251\u001b[0m lday \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolators[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasin][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdayl\u001b[39m\u001b[38;5;124m'\u001b[39m](t_np, extrapolate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiodic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    252\u001b[0m lday \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(lday, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type_torch)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_eval)\n\u001b[0;32m--> 254\u001b[0m p_snow \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msinh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_snow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m p_rain \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(torch\u001b[38;5;241m.\u001b[39msinh(p_rain))\n\u001b[1;32m    256\u001b[0m m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_function(s0) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msinh(m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for basin in all_basins:\n",
    "\n",
    "    # Temporary basin configuration file\n",
    "    basin_file = f'temp_basin_{basin}_{nn_type}.txt'\n",
    "    with open(basin_file, 'w') as f:\n",
    "        f.write(basin)\n",
    "\n",
    "    # Update the basin configuration file\n",
    "    cfg['basin_file'] = basin_file\n",
    "\n",
    "    # Create temporary configuration file config_file_temp_basin.yml\n",
    "    config_file_temp = str(config_file).split('.')[0] + f'_temp_{nn_type}_{basin}.yml'\n",
    "    with open(config_file_temp, 'w') as f:\n",
    "        yaml.dump(cfg, f)\n",
    "\n",
    "    # Load the configuration file and dataset\n",
    "    cfg_run, dataset = _load_cfg_and_ds(\n",
    "        Path(config_file_temp), model='hybrid')\n",
    "\n",
    "    # Delete the basin_file and config_file_temp after training\n",
    "    if os.path.isfile(basin_file):\n",
    "        os.remove(basin_file)\n",
    "    if os.path.isfile(config_file_temp):\n",
    "        os.remove(config_file_temp)\n",
    "\n",
    "    # Get the basin interpolators\n",
    "    interpolators = get_basin_interpolators(dataset, cfg_run, project_dir)\n",
    "\n",
    "    # Conceptual model\n",
    "    time_idx0 = 0\n",
    "    model_concept = get_concept_model(cfg_run, dataset.ds_train, \n",
    "                                      interpolators, time_idx0, \n",
    "                                      dataset.scaler)\n",
    "\n",
    "    # Neural network model\n",
    "    model_nn = get_nn_model(model_concept, dataset.ds_static)\n",
    "\n",
    "    # Pretrainer\n",
    "    pretrainer = get_nn_pretrainer(model_nn, dataset)\n",
    "\n",
    "    # Pretrain the model\n",
    "    pretrain_ok = pretrainer.train(loss=cfg_run.loss_pretrain, \n",
    "                                lr=cfg_run.lr_pretrain, \n",
    "                                epochs=cfg_run.epochs_pretrain,\n",
    "                                disable_pbar=False,\n",
    "                                any_log=False\n",
    "    )\n",
    "    \n",
    "    # Train the hybrid model\n",
    "    if pretrain_ok:\n",
    "        # Build the hybrid model\n",
    "        model_hybrid = get_hybrid_model(cfg_run, pretrainer, dataset)\n",
    "\n",
    "        # Build the trainer \n",
    "        trainer = get_trainer(model_hybrid)\n",
    "\n",
    "        # Train the model \n",
    "        trainer.train()\n",
    "    else:\n",
    "        print(f'Pretraining failed for basin {basin}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to explore the methods *evaluate* and *save_plots* in the class *BaseHybridModelTrainer* (*src/modelzoo_hybrid/basetrainer*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-hydronodes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
